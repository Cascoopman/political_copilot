# Political Copilot
## Goal 
The goal of this internship project was to help citizens navigate the political ecosphere of Flanders by leveraging the power of LLM Agents.

With the federal elections nearing, the need for clarity in an abundance of information arose. The idea was to have LLM agents autonomously analyse government documents, faction websites and news articles to generate a comprehensive answer to the user query.

In general, using multiple agents results in a more dynamic, detailed and grounded analysis of the political landscape partly due to fact-checking. Other benefits of using agents is that they each have a tailored RAG system, custom tools, independent context window and can be entirely parallelized.

Ultimately, comparing the responses of the agents with an intuitive slider and including the detailed reasoning makes navigating the political ecosphere a breeze.


## How does it work?
To put it simply, a user query is passed to a moderator, which asks the viewpoints of each faction. This is generated by an agent representing the faction in the virtual debate. After each agent is done generating, a summarizer collects and summarizes the debate before outputting it to the user. 

Here's a demo!

https://github.com/user-attachments/assets/e64cea03-c075-4f6b-949a-662b5b686991

To put it less simply, the system first creates the agents based on data about the faction representing its history and values. The agent that embodies the faction then collects data that is relevant for generating a stance on the user query. Before or after generating a viewpoint, each agent has to ability to call upon other tools. These tools can be shared, reusable components or private custom tools. Other agents can also be wrapped inside a tool. Finally, their generated responses are further processed to fact check, add sources and return a coherent output.

As for the tech-stack, we use [Fondant](https://fondant.ai/en/latest/) to create data pipelines. This tools allows for easy collaboration when crafting big data. The data for the RAG is chunked, embedded and stored in a GCP Vector Search according to a [specific JSON schema](https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure#input_data_storage_and_file_organization). We explored the [Autogen](https://github.com/microsoft/autogen/tree/main) library, it has different agent orchestration methods. But ultimately, our standard conversation is a hard-coded single turn debate where the agents do not see the output of other agents. Finally, we use [Streamlit](https://github.com/streamlit/streamlit) to create the User Interface where we return the output to the user. The entire system's cloud infrastructure is built using [Nimbus](https://www.ml6.eu/domains/infrastructure), an ML6 in-house cloud deployment boilerplate, and [Terraform](https://www.terraform.io/).

## How can I contribute?
There are two key parts in this system: the data and the agents. 

This tool depends heavily on the quality and amount of data it is fed. You can add data to the [Vector DB](https://github.com/jBontinck/political_copilot/tree/main/src/pipelines). We welcome any data that adheres to the prescribed schemas. Or you can add data from within a tool call.

Which brings us to the agents. You can add [tools or orchestration methods](https://github.com/jBontinck/political_copilot/tree/main/src/backend/src).

## Codebase 
Before you can deploy this system, make sure to first setup the Vector Search, the backend and the frontend. To actually deploy or undeploy the system, run the deploy and undeploy scripts. Be sure to first set your $GCP_PROJECT_NAME, $GCP_VS_INDEX and $GCP_VS_ENDPOINT variables.

## Cloud Architecture

![Cloud-Architecture](https://github.com/user-attachments/assets/1aed3fbe-61c8-4370-8669-86acd2b0b8d4)

## Multi-Agent API

![MultiAgent-API](https://github.com/user-attachments/assets/b7b035e9-914c-449b-9f06-6a434be0771c)

_For questions or feedback, contact us at:_
_jensbontinck@gmail.com_ and
_cascoopman@hotmail.com_
